{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Deep Learning Models with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Examples with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.3147\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1987\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2254\n",
      "Epoch [1/5], Step [400/600], Loss: 0.2082\n",
      "Epoch [1/5], Step [500/600], Loss: 0.2227\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.69 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.4029, -13.6164,  -6.6096,   0.2275,  -5.1154,  -8.5581, -13.3805,\n",
       "          -0.7737,  -3.6062,  11.4983]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_batch = next(iter(test_loader))\n",
    "k = 99\n",
    "one_image = one_batch[0][k]\n",
    "one_label = one_batch[1][k]\n",
    "\n",
    "one_image_npy = one_image.squeeze().numpy()\n",
    "plt.imshow(one_image_npy, cmap='gray')\n",
    "\n",
    "image = one_image.reshape(1,28*28).to(device)\n",
    "label = one_label.to(device)\n",
    "print(one_label)\n",
    "model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
